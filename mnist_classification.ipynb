{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tiago-mendonca/dotfiles/blob/master/mnist_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNxEh1PCPTzF"
      },
      "source": [
        "# MNIST Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYPoxA5tPTzH"
      },
      "source": [
        "üéØ <b><u>Exercise objectives</u></b>\n",
        "- Understand the *MNIST* dataset \n",
        "- Design your first **Convolutional Neural Network** (*CNN*) and answer questions such as:\n",
        "    - what are *Convolutional Layers*? \n",
        "    - how many *parameters* are involved in such a layer?\n",
        "- Train this CNN on images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mqPzea7JPTzI"
      },
      "source": [
        "üöÄ <b><u>Let's get started!</u></b>\n",
        "\n",
        "Imagine that we are  back in time into the 90's.\n",
        "You work at a *Post Office* and you have to deal with an enormous amount of letters on a daily basis. How could you automate the process of reading the ZIP Codes, which are a combination of 5 handwritten digits? \n",
        "\n",
        "This task, called the **Handwriting Recognition**, used to be a very complex problem back in those days. It was solved by *Bell Labs* (among others) where one of the Deep Learning gurus, *Yann Le Cun* used to work.\n",
        "\n",
        "From [Wikipedia](https://en.wikipedia.org/wiki/Handwriting_recognition):\n",
        "\n",
        "> Handwriting recognition (HWR), also known as Handwritten Text Recognition (HTR), is the ability of a computer to receive and interpret intelligible handwritten input from sources such as paper documents, photographs, touch-screens and other devices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0G8erskQPTzI"
      },
      "source": [
        "![Number recognition](recognition.gif)\n",
        "\n",
        "*Note: The animation above is just here to help you visualize what happens with the different images: <br/> $\\rightarrow$ For each image, the CNN predicts what digit is written. The inputs are the different digits and not one animation/video!*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DkzyeKV2PTzJ"
      },
      "source": [
        "ü§î <b><u>How does this CNN work ?</u></b>\n",
        "\n",
        "- *Inputs*: Images (_each image shows a handwritten digit_)\n",
        "- *Target*: For each image, you want your CNN model to predict the correct digit (between 0 and 9)\n",
        "    - It is a **multi-class classification** task (more precisely a 10-class classification task since there are 10 different digits).\n",
        "\n",
        "üî¢ To improve the capacity of the Convolutional Neural Network to read these numbers, we need to feed it with many images representing handwritten digits. This is why the üìö [**MNIST dataset**] üìö(http://yann.lecun.com/exdb/mnist/) *(Mixed National Institute of Standards and Technology)* was created."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "BbyGETzmPTzJ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMt2BV_jPTzK"
      },
      "source": [
        "## (1) The `MNIST` Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1UI4KtqbPTzK"
      },
      "source": [
        "üìö Tensorflow/Keras offers multiple [**datasets**](https://www.tensorflow.org/api_docs/python/tf/keras/datasets) to play with:\n",
        "- *Vectors*: `boston_housing` (regression)\n",
        "- *Images* : `mnist`, `fashion_mnist`, `cifar10`, `cifar100` (classification)\n",
        "- *Texts*: `imbd`, `reuters` (classification/sentiment analysis)\n",
        "\n",
        "\n",
        "üíæ You can **load the MNIST dataset** with the following commands:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68hrgvXiPTzL",
        "outputId": "f53bed25-9dc7-449f-b4fb-17c49dd8c970"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras import datasets\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = datasets.mnist.load_data(path=\"mnist.npz\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "548xCdEyPTzM"
      },
      "source": [
        "### (1.1) Exploring the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "johY55A0PTzM"
      },
      "source": [
        "‚ùì **Question: Let's have look at some handwritten digits of this MNIST dataset.** ‚ùì\n",
        "\n",
        "üñ® Print some images from the *train set*.\n",
        "\n",
        "<details>\n",
        "    <summary><i>Hints</i></summary>\n",
        "\n",
        "üí°*Hint*: use the `imshow` function from `matplotlib` with `cmap = \"gray\"`\n",
        "\n",
        "ü§® Note: if you don't specify this *cmap* argument, the weirdly displayed colors are just Matplotlib defaults...\n",
        "    \n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "tags": [
          "challengify"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "id": "tZ4TAP7mPTzM",
        "outputId": "1a8b48df-24e0-46f2-e74e-b7f7281412f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "print(X_train.shape)\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(X_train[0], cmap=\"gray\");\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(X_train[1], cmap=\"gray\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6fGtPzVPTzN"
      },
      "source": [
        "### (1.2) Image Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "juiP3fmHPTzN"
      },
      "source": [
        "‚ùóÔ∏è **Neural Networks converge faster when the input data is somehow normalized** ‚ùóÔ∏è\n",
        "\n",
        "üë©üèª‚Äçüè´ How do we proceed for Convolutional Neural Networks ?\n",
        "* The `RBG` intensities are coded between 0 and 255. \n",
        "* We can simply divide the input data by the maximal value 255 to have all the pixels' intensities between 0 and 1 üòâ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ZbMZ3FmPTzN"
      },
      "source": [
        "‚ùì **Question: As a first preprocessing step, please normalize your data.** ‚ùì\n",
        "\n",
        "Don't forget to do it both on your train data and your test data.\n",
        "\n",
        "(*Note: you can also center your data, by subtracting 0.5 from all the values, but it is not mandatory*)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "tags": [
          "challengify"
        ],
        "id": "2GmRDdL8PTzN"
      },
      "outputs": [],
      "source": [
        "X_train = X_train / 255.\n",
        "X_test = X_test / 255."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPaLvEPgPTzO"
      },
      "source": [
        "### (1.3) Inputs' dimensionality"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-f4mEepPTzO"
      },
      "source": [
        "‚ùì **Question: What is the shape of your images** ‚ùì"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "tags": [
          "challengify"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PurAIoZnPTzO",
        "outputId": "2613a83c-d184-435a-e144-ed023b70352d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28)\n",
            "(10000, 28, 28)\n",
            "(60000,)\n",
            "(10000,)\n"
          ]
        }
      ],
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmlUl6fRPTzO"
      },
      "source": [
        "üëÜ You see that you have 60,000 training images, all of size $(28, 28)$. However...\n",
        "\n",
        "‚ùóÔ∏è  **`Convolutional Neural Network models need to be fed with images whose last dimension is the number of channels`** ‚ùóÔ∏è\n",
        "\n",
        "This last dimension is clearly missing here... Can you guess the reason why?\n",
        "\n",
        "<details>\n",
        "    <summary><i>Answer<i></summary>\n",
        "        \n",
        "* All these $60000$ $ 28 \\times 28 $ pictures are black-and-white. $ \\implies $ Each pixel lives on a spectrum from full black (0) to full white (1)\n",
        "        \n",
        "* Theoretically, you don't need to know the number of channels unlike colored pictures using for example:\n",
        "    - the RGB system with 3 channels (<b><span style=\"color:red\">Red</span> <span style=\"color:green\">Green</span> <span style=\"color:blue\">Blue</span></b>)\n",
        "    - the CYMK system  with 4 channels (<b><span style=\"color:cyan\">Cyan</span> <span style=\"color:magenta\">Magenta</span> <span style=\"color:yellow\">Yellow</span> <span style=\"color:black\">Black</span> </b>)\n",
        "        \n",
        "        \n",
        "</details>        "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1rHtuOFPTzO"
      },
      "source": [
        "‚ùì **Question: expanding dimensions** ‚ùì\n",
        "\n",
        "* Use the **expand_dims** to add one dimension at the end of the training data and test data.\n",
        "\n",
        "* Then, print the shapes of `X_train` and `X_test` which should respectively be equal to $(60000, 28, 28, 1)$ and $(10000, 28, 28, 1)$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "676-xtyxPTzP"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.backend import expand_dims"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6qxiYbfPTzP",
        "outputId": "183242c2-a8df-4a93-f003-fb05f7bde9e8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# Reshape the X to explicitly add a single \"color\" channel\n",
        "X_train = X_train.reshape(len(X_train), 28, 28, 1)\n",
        "X_test = X_test.reshape(len(X_test), 28, 28, 1)\n",
        "X_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1DlKZyWPTzP"
      },
      "source": [
        "### (1.4) Label encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ms5WwcdYPTzP"
      },
      "source": [
        "One more thing to do to prepare your data is to convert your labels to \"*one-hot encode*\" the categories.\n",
        "\n",
        "‚ùì **Question: encoding the labels** ‚ùì \n",
        "\n",
        "* Use **`to_categorical`** to transform your labels. \n",
        "* Store the results into two variables that you can call **`y_train_cat`** and **`y_test_cat`**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJFty7-aPTzP",
        "outputId": "50503754-1f1d-455f-a6cc-7f057f050e71"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y_cat_train = to_categorical(y_train, num_classes=10)\n",
        "y_cat_test = to_categorical(y_test, num_classes=10)\n",
        "y_cat_train.shape\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMcSvKnhPTzP"
      },
      "source": [
        "The data is now ready to be used. ‚úÖ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRl1n5kHPTzQ"
      },
      "source": [
        "## (2) The Convolutional Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7YrAr7CPTzQ"
      },
      "source": [
        "### (2.1) Architecture and compilation of a CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQDLbneNPTzQ"
      },
      "source": [
        "\n",
        "‚ùì **Question: CNN Architecture and compilation** ‚ùì\n",
        "\n",
        "Now, let's build a <u>Convolutional Neural Network</u> that has: \n",
        "\n",
        "\n",
        "- a `Conv2D` layer with 8 filters, each of size $(4, 4)$, an input shape suitable for your task, the `relu` activation function, and `padding='same'`\n",
        "- a `MaxPool2D` layer with a `pool_size` equal to $(2, 2)$\n",
        "- a second `Conv2D` layer with 16 filters, each of size $(3, 3)$, and the `relu` activation function\n",
        "- a second `MaxPool2D` layer with a `pool_size` equal to $(2, 2)$\n",
        "\n",
        "\n",
        "- a `Flatten` layer\n",
        "- a first `Dense` layer with 10 neurons and the `relu` activation function\n",
        "- a last (predictive) layer that is suited for your task\n",
        "\n",
        "In the function that initializes this model, do not forget to include the <u>compilation of the model</u>, which:\n",
        "* optimizes the `categorical_crossentropy` \n",
        "* with the `adam` optimizer\n",
        "* and the `accuracy` as the metrics\n",
        "\n",
        "(*Note: you could add more classification metrics if you want but the dataset is well balanced!*)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Z57zgC6wPTzQ"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import models\n",
        "\n",
        "\n",
        "def initialize_model():\n",
        "\n",
        "    model = models.Sequential()\n",
        "\n",
        "    ### First Convolution & MaxPooling\n",
        "    model.add(layers.Conv2D(8, (4,4), input_shape=(28, 28, 1), padding='same', activation=\"relu\"))\n",
        "    model.add(layers.MaxPool2D(pool_size=(2,2)))\n",
        "    \n",
        "    ### Second Convolution & MaxPooling\n",
        "    model.add(layers.Conv2D(16, (3,3), activation=\"relu\"))\n",
        "    model.add(layers.MaxPool2D(pool_size=(2,2)))\n",
        "\n",
        "    ### Flattening\n",
        "    model.add(layers.Flatten())\n",
        "    \n",
        "    ### One Fully Connected layer - \"Fully Connected\" is equivalent to saying \"Dense\"\n",
        "    model.add(layers.Dense(10, activation='relu'))\n",
        "    \n",
        "    ### Last layer - Classification Layer with 10 outputs corresponding to 10 digits\n",
        "    model.add(layers.Dense(10, activation='softmax'))\n",
        "    \n",
        "    ### Model compilation\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "    \n",
        "    return model\n",
        "    \n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LaojR1WuPTzQ"
      },
      "source": [
        "‚ùì **Question: number of trainable parameters in a convolutional layer** ‚ùì \n",
        "\n",
        "How many trainable parameters are there in your model?\n",
        "1. Compute them with ***model.summary( )*** first\n",
        "2. Recompute them manually to make sure you properly understood ***what influences the number of weights in a CNN***."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "tags": [
          "challengify"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a6n41awlPTzQ",
        "outputId": "da4eab6f-d336-4ebb-8073-38182f80e4be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_2 (Conv2D)           (None, 28, 28, 8)         136       \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 14, 14, 8)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 12, 12, 16)        1168      \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 6, 6, 16)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 576)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                5770      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                110       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7,184\n",
            "Trainable params: 7,184\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = initialize_model()\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#params_per_layer = kernel_shape * chanels * filters + bias_per_filter"
      ],
      "metadata": {
        "id": "9n7dUjZ7amZv"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count_params = ((4*4) * 1 * 8 + 8) + ((3*3)* 8 * 16 + 16) \n",
        "count_params"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwgwRN0EV49K",
        "outputId": "b93c83e8-ff8f-4294-d53e-4ab6b057fecf"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1304"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFSoQtP9PTzQ"
      },
      "source": [
        "### (2.2) Training a CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uejTNxBaPTzQ"
      },
      "source": [
        "‚ùì **Question: training a CNN** ‚ùì \n",
        "\n",
        "Initialize your model and fit it on the train data. \n",
        "- Do not forget to use a **Validation Set/Split** and an **Early Stopping criterion**. \n",
        "- Limit yourself to 5 epochs max in this challenge, just to save some precious time for the more advanced challenges!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1JQIdEbGPTzR",
        "outputId": "e09ff128-1172-4be5-8b8d-26ce93f40a23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "2625/2625 [==============================] - 21s 4ms/step - loss: 0.4629 - accuracy: 0.8502 - val_loss: 0.1575 - val_accuracy: 0.9536\n",
            "Epoch 2/5\n",
            "2625/2625 [==============================] - 10s 4ms/step - loss: 0.1258 - accuracy: 0.9627 - val_loss: 0.1187 - val_accuracy: 0.9652\n",
            "Epoch 3/5\n",
            "2625/2625 [==============================] - 10s 4ms/step - loss: 0.0927 - accuracy: 0.9715 - val_loss: 0.0905 - val_accuracy: 0.9736\n",
            "Epoch 4/5\n",
            "2625/2625 [==============================] - 10s 4ms/step - loss: 0.0769 - accuracy: 0.9766 - val_loss: 0.0849 - val_accuracy: 0.9754\n",
            "Epoch 5/5\n",
            "2625/2625 [==============================] - 10s 4ms/step - loss: 0.0669 - accuracy: 0.9797 - val_loss: 0.0897 - val_accuracy: 0.9741\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "es= EarlyStopping(patience=30)\n",
        "model = initialize_model()\n",
        "\n",
        "history= model.fit(X_train, y_cat_train,\n",
        "                    validation_split= 0.3,\n",
        "                    epochs= 5,\n",
        "                    batch_size= 16,\n",
        "                    verbose= 1,\n",
        "                    callbacks= [es])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcDT8-DdPTzR"
      },
      "source": [
        "‚ùì **Question: How many iterations does the CNN perform per epoch** ‚ùì\n",
        "\n",
        "_Note: it has nothing to do with the fact that this is a CNN. This is related to the concept of forward/backward propagation already covered during the previous lecture on optimizers, fitting, and losses üòâ_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "challengify"
        ],
        "id": "RaZ3n5IxPTzR"
      },
      "source": [
        "> YOUR ANSWER HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJ61lAjJPTzR"
      },
      "source": [
        "<details>\n",
        "    <summary><i>Answer:</i></summary>\n",
        "\n",
        "With `verbose = 1` when fitting your model, you have access to crucial information about your training procedure.\n",
        "    \n",
        "Remember that we've just trained our CNN model on $60000$ training images\n",
        "\n",
        "If the chosen batch size is 32: \n",
        "\n",
        "* For each epoch, we have $ \\large \\lceil \\frac{60000}{32} \\rceil = 1875$ minibatches <br/>\n",
        "* The _validation_split_ is equal to $0.3$ - which means that within one single epoch, there are:\n",
        "    * $ \\lceil 1875 \\times (1 - 0.3) \\rceil = \\lceil 1312.5 \\rceil = 1313$ batches are used to compute the `train_loss` \n",
        "    * $ 1875 - 1312 = 562 $ batches are used to compute the `val_loss`\n",
        "    * **The parameters are updated 1313 times per epoch** as there are 1313 forward/backward propagations per epoch !!!\n",
        "\n",
        "\n",
        "üëâ With so many updates of the weights within one epoch, you can understand why this CNN model converges even with a limited number of epochs.\n",
        "\n",
        "</details>    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlQdzJ05PTzR"
      },
      "source": [
        "### (2.3) Evaluating its performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOrk_pIyPTzR"
      },
      "source": [
        "‚ùì **Question: Evaluating your CNN** ‚ùì \n",
        "\n",
        "What is your **`accuracy on the test set?`**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "tags": [
          "challengify"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EzTbgOG6PTzR",
        "outputId": "02cfc313-19fc-4792-b14a-1a4c344f1e17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0757 - accuracy: 0.9754\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9753999710083008"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "accuracy = model.evaluate(X_test, y_cat_test, verbose=1)[1]\n",
        "accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDsGY_NPPTzR"
      },
      "source": [
        "üéâ You should already be impressed by your CNN skills! Reaching over 95% accuracy!\n",
        "\n",
        "üî• You solved what was a very hard problem 30 years ago with your own CNN."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vcVnrd5SPTzR"
      },
      "source": [
        "üèÅ **Congratulations!**\n",
        "\n",
        "üíæ Don't forget to `git add/commit/push` your notebook...\n",
        "\n",
        "üöÄ ... and move on to the next challenge!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3T8XuR7JPTzS"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "name": "mnist_classification.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}